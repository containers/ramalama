# Base image with CUDA for compilation
FROM docker.io/nvidia/cuda:12.6.2-devel-ubi9 AS builder

ARG LLAMA_CPP_SHA=af148c9386da825a60c7038549c121c35ca56b50
# renovate: datasource=git-refs depName=ggerganov/whisper.cpp packageName=https://github.com/ggerganov/whisper.cpp gitRef=master versioning=loose type=digest
ARG WHISPER_CPP_SHA=01d3bd7d5ccd1956a7ddf1b57ee92d69f35aad93

COPY ../scripts /scripts
RUN chmod +x /scripts/*.sh && \
    /scripts/build_llama_and_whisper.sh "cuda" "$LLAMA_CPP_SHA" \
      "$WHISPER_CPP_SHA" "/tmp/install" \
      "-DGGML_CUDA=ON" "-DCMAKE_EXE_LINKER_FLAGS=-Wl,--allow-shlib-undefined"

# Final runtime image
FROM docker.io/nvidia/cuda:12.6.2-runtime-ubi9

RUN dnf install -y python3 && \
    dnf clean all && rm -rf /var/cache/*dnf*

# Copy the entire installation directory from the builder
COPY --from=builder /tmp/install /usr


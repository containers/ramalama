ARG VERSION=12.8.1
# Base image with CUDA for compilation
FROM docker.io/nvidia/cuda:${VERSION}-devel-ubi9 AS builder

COPY . /src/ramalama
WORKDIR /src/ramalama
RUN container-images/scripts/build_llama_and_whisper.sh cuda

# Final runtime image
FROM docker.io/nvidia/cuda:${VERSION}-runtime-ubi9

# Copy the entire installation directory from the builder
COPY --from=builder /tmp/install /usr

# Workaround for CUDA libraries not in the ld path in base container
RUN echo "/usr/local/cuda-12.8/compat" > /etc/ld.so.conf.d/99_cuda_compat.conf && ldconfig

RUN dnf install -y python3.11 python3.11-pip python3.11-devel && \
    dnf -y clean all && \
    ln -sf /usr/bin/python3.11 /usr/bin/python3

ENTRYPOINT []

FROM registry.access.redhat.com/ubi9/ubi:9.4-1214.1729773476

# renovate: datasource=github-releases depName=huggingface/huggingface_hub extractVersion=^v(?<version>.*)
ARG HUGGINGFACE_HUB_VERSION=0.26.2
# renovate: datasource=github-releases depName=containers/omlmd extractVersion=^v(?<version>.*)
ARG OMLMD_VERSION=0.1.6
# renovate: datasource=github-releases depName=tqdm/tqdm extractVersion=^v(?<version>.*)
ARG TQDM_VERSION=4.66.6
ARG LLAMA_CPP_SHA=1329c0a75e6a7defc5c380eaf80d8e0f66d7da78
# renovate: datasource=git-refs depName=ggerganov/whisper.cpp packageName=https://github.com/ggerganov/whisper.cpp gitRef=master versioning=loose type=digest
ARG WHISPER_CPP_SHA=0377596b77a3602e36430320cbe45f8c305ef04a

# vulkan-headers vulkan-loader-devel vulkan-tools glslc glslang python3-pip mesa-libOpenCL-$MESA_VER.aarch64
RUN dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm && \
    crb enable && \
    dnf install -y epel-release && \
    dnf --enablerepo=ubi-9-appstream-rpms install -y git procps-ng vim \
      dnf-plugins-core python3-dnf-plugin-versionlock cmake gcc-c++ \
      python3-pip python3-argcomplete && \
    dnf copr enable -y slp/mesa-krunkit epel-9-$(uname -m) && \
    dnf install -y mesa-vulkan-drivers-23.3.3-102.el9 \
      vulkan-headers vulkan-loader-devel vulkan-tools spirv-tools glslc && \
    dnf clean all && \
    rm -rf /var/cache/*dnf*

RUN /usr/bin/python3 --version
RUN pip install "huggingface_hub==${HUGGINGFACE_HUB_VERSION}"
RUN pip install "omlmd==${OMLMD_VERSION}"
RUN pip install "tqdm==${TQDM_VERSION}"

RUN dnf config-manager --add-repo \
      https://mirror.stream.centos.org/9-stream/AppStream/$(uname -m)/os/
RUN curl --retry 8 --retry-all-errors -o \
      /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-Official \
      http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-Official && \
      cat /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-Official
RUN rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-Official
RUN dnf install -y glslang && \
    dnf clean all && \
    rm -rf /var/cache/*dnf*

RUN git clone --recursive https://github.com/ggerganov/llama.cpp && \
    cd llama.cpp && \
    git reset --hard ${LLAMA_CPP_SHA} && \
    cmake -B build -DCMAKE_INSTALL_PREFIX:PATH=/usr -DGGML_KOMPUTE=1 \
      -DGGML_CCACHE=0 && \
    cmake --build build --config Release -j $(nproc) && \
    cmake --install build && \
    cd / && \
    rm -rf llama.cpp

RUN git clone https://github.com/ggerganov/whisper.cpp.git && \
    cd whisper.cpp && \
    git reset --hard ${WHISPER_CPP_SHA} && \
    cmake -B build -DCMAKE_INSTALL_PREFIX:PATH=/usr -DGGML_KOMPUTE=1 \
      -DGGML_CCACHE=0 && \
    cmake --build build --config Release -j $(nproc) && \
    mv build/bin/main /usr/bin/whisper-main && \
    mv build/bin/server /usr/bin/whisper-server && \
    cd / && \
    rm -rf whisper.cpp

ENV WHISPER_CPP_SHA=${WHISPER_CPP_SHA}
ENV LLAMA_CPP_SHA=${LLAMA_CPP_SHA}

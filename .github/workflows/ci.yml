name: ci

on:
  pull_request:
  push:
    branches:
      - main

jobs:
  lint:
    name: Lint Code
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
      - name: Install dependencies
        shell: bash
        run: |
          sudo apt-get update
          sudo apt-get install -y bash codespell python3-argcomplete pipx
          make install-requirements

      - name: Run format check
        run: |
          make check-format

      - name: Run lint
        run: |
          make lint

  bats:
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
      - name: install bats
        shell: bash
        run: |
           sudo apt-get update
           sudo apt-get install podman bats bash codespell python3-argcomplete pipx
           make install-requirements

      - name: install ollama and hf-cli
        shell: bash
        run: |
           sudo curl -fsSL https://ollama.com/install.sh | sh
           pip install -U "huggingface_hub[cli]"

      - name: Upgrade to podman 5
        run: |
           set -e
           # Enable universe repository which contains podman
           sudo add-apt-repository "deb http://archive.ubuntu.com/ubuntu oracular universe"
           # Update package lists
           sudo apt-get update
           sudo apt-get purge firefox
           # Install specific podman version
           sudo apt-get upgrade

      - name: Build a container for CPU inferencing
        run: ./container_build.sh build ramalama

      - name: run bats
        run: |
           make validate
           make bats

  bats-nocontainer:
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
      - name: install bats
        shell: bash
        run: |
           sudo apt-get update
           sudo apt-get install podman bats bash codespell python3-argcomplete pipx git cmake libcurl4-openssl-dev
           make install-requirements
           sudo ./container-images/scripts/build_llama_and_whisper.sh

      - name: install ollama and hf-cli
        shell: bash
        run: |
           sudo curl -fsSL https://ollama.com/install.sh | sh
           pip install -U "huggingface_hub[cli]"

      - name: Upgrade to podman 5
        run: |
           set -e
           # Enable universe repository which contains podman
           sudo add-apt-repository "deb http://archive.ubuntu.com/ubuntu oracular universe"
           # Update package lists
           sudo apt-get update
           sudo apt-get purge firefox
           # Install specific podman version
           sudo apt-get upgrade

      - name: bats-nocontainer
        run: |
           make bats-nocontainer

  docker:
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
      - name: install bats
        shell: bash
        run: |
           sudo apt-get update
           sudo apt-get install bats bash codespell python3-argcomplete pipx
           make install-requirements

      - name: install ollama and hf-cli
        shell: bash
        run: |
           sudo curl -fsSL https://ollama.com/install.sh | sh
           pip install -U "huggingface_hub[cli]"

      - name: Upgrade to podman 5
        run: |
           set -e
           # Enable universe repository which contains podman
           sudo add-apt-repository "deb http://archive.ubuntu.com/ubuntu oracular universe"
           # Update package lists
           sudo apt-get update
           sudo apt-get purge firefox
           # Install specific podman version
           sudo apt-get upgrade

      - name: Free Disk Space Linux
        shell: bash
        run: |
           sudo docker rmi "$(docker image ls -aq)" >/dev/null 2>&1 || true
           sudo rm -rf \
              /usr/share/dotnet /usr/local/lib/android /opt/ghc \
              /usr/local/share/powershell /usr/share/swift /usr/local/.ghcup \
              /usr/lib/jvm || true

      # /mnt has ~ 65 GB free disk space. / is too small.
      - name: Reconfigure Docker data-root
        run: |
           sudo mkdir -p /mnt/docker /etc/docker
           echo '{"data-root": "/mnt/docker"}' > /tmp/daemon.json
           sudo mv /tmp/daemon.json /etc/docker/daemon.json
           cat /etc/docker/daemon.json
           sudo systemctl restart docker.service
           df -h

      - name: Build a container for CPU inferencing
        run: ./container_build.sh build ramalama

      - name: bats-docker
        run: |
           docker info
           make bats-docker

  macos:
    runs-on: macos-14
    steps:
      - uses: actions/checkout@v4
      - name: install golang
        shell: bash
        run: |
           brew install go bats bash jq llama.cpp
           make install-requirements

      - name: install ollama and hf-cli
        shell: bash
        run: |
           brew install ollama huggingface-cli

      - name: Run a one-line script
        shell: bash
        run: |
           make install-requirements
           make validate
           pipx install .
           make bats-nocontainer

# FIXME: ci script should be able to run on MAC.
#      - name: Run ci
#        shell: bash
#        run: make ci

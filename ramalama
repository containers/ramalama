#!/usr/bin/python3

import os
import glob
import sys
import subprocess
import json
import hashlib
import shutil
import time
import re
from pathlib import Path

x = False
funcDict = {}


def verify_checksum(filename):
    """
    Verifies if the SHA-256 checksum of a file matches the checksum provided in the filename.

    Args:
    filename (str): The filename containing the checksum prefix (e.g., "sha256:<checksum>")

    Returns:
    bool: True if the checksum matches, False otherwise.
    """

    if not os.path.exists(filename):
        return False

    # Check if the filename starts with "sha256:"
    fn_base = os.path.basename(filename)
    if not fn_base.startswith("sha256:"):
        raise ValueError(f"Filename does not start with 'sha256:': {fn_base}")

    # Extract the expected checksum from the filename
    expected_checksum = fn_base.split(":")[1]
    if len(expected_checksum) != 64:
        raise ValueError("Invalid checksum length in filename")

    # Calculate the SHA-256 checksum of the file contents
    sha256_hash = hashlib.sha256()
    with open(filename, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)

    # Get the calculated checksum
    calculated_checksum = sha256_hash.hexdigest()

    # Compare the checksums
    return calculated_checksum == expected_checksum


def print_error(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)


def run_cmd(args):
    if x:
        print(*args)

    return subprocess.run(args, check=True, stdout=subprocess.PIPE)


def run_curl_cmd(args, filename):
    if not verify_checksum(filename):
        try:
            run_cmd(args)
        except subprocess.CalledProcessError as e:
            if e.returncode == 22:
                print_error(filename + " not found")
            sys.exit(e.returncode)


def pull_ollama_manifest(repos_ollama, manifests, accept, registry_head, model_tag):
    os.makedirs(os.path.dirname(manifests), exist_ok=True)
    os.makedirs(os.path.join(repos_ollama, "blobs"), exist_ok=True)
    curl_cmd = [
        "curl", "-f", "-s", "--header", accept,
        "-o", manifests,
        f"{registry_head}/manifests/{model_tag}"
    ]
    run_cmd(curl_cmd)


def pull_ollama_config_blob(repos_ollama, accept, registry_head, manifest_data):
    cfg_hash = manifest_data["config"]["digest"]
    config_blob_path = os.path.join(repos_ollama, "blobs", cfg_hash)
    curl_cmd = [
        "curl", "-f", "-s", "-L", "-C", "-", "--header", accept,
        "-o", config_blob_path,
        f"{registry_head}/blobs/{cfg_hash}"
    ]
    run_curl_cmd(curl_cmd, config_blob_path)


def pull_ollama_blob(repos_ollama, layer_digest, accept, registry_head, ramalama_models, model_name, model_tag, symlink_path):
    layer_blob_path = os.path.join(repos_ollama, "blobs", layer_digest)
    curl_cmd = ["curl", "-f", "-L", "-C", "-", "--progress-bar", "--header",
                accept, "-o", layer_blob_path, f"{registry_head}/blobs/{layer_digest}"]
    run_curl_cmd(curl_cmd, layer_blob_path)
    os.makedirs(ramalama_models, exist_ok=True)
    relative_target_path = os.path.relpath(
        layer_blob_path, start=os.path.dirname(symlink_path))
    try:
        run_cmd(["ln", "-sf", relative_target_path, symlink_path])
    except subprocess.CalledProcessError as e:
        print_error(e)
        sys.exit(e.returncode)


def init_pull(repos_ollama, manifests, accept, registry_head, model_name, model_tag, ramalama_models, symlink_path, model):
    try:
        pull_ollama_manifest(repos_ollama, manifests,
                             accept, registry_head, model_tag)
        with open(manifests, 'r') as f:
            manifest_data = json.load(f)
    except subprocess.CalledProcessError as e:
        if e.returncode == 22:
            print_error(model + ":" + model_tag + " not found")
        sys.exit(e.returncode)

    pull_ollama_config_blob(repos_ollama, accept,
                            registry_head, manifest_data)
    for layer in manifest_data["layers"]:
        layer_digest = layer["digest"]
        if layer["mediaType"] != 'application/vnd.ollama.image.model':
            continue

        pull_ollama_blob(repos_ollama, layer_digest, accept,
                         registry_head, ramalama_models, model_name, model_tag, symlink_path)

    return symlink_path


def huggingface_download(ramalama_store, directory, filename, repo_dir):
    return run_cmd(["huggingface-cli", "download", directory, filename, "--cache-dir", ramalama_store + "/repos/huggingface/.cache", "--local-dir", repo_dir])


def try_huggingface_download(ramalama_store, model, directory, filename):
    repo_dir = f"{ramalama_store}/repos/huggingface/{directory}/{model}"
    os.makedirs(repo_dir, exist_ok=True)
    huggingface_download(ramalama_store, directory, filename, repo_dir)
    return f"{ramalama_store}/repos/huggingface/{directory}/{model}/{filename}"


def mkdirs(ramalama_store):
    # List of directories to create
    directories = [
        'models/huggingface',
        'repos/huggingface',
        'models/ollama',
        'repos/ollama'
    ]

    # Create each directory
    for directory in directories:
        full_path = os.path.join(ramalama_store, directory)
        os.makedirs(full_path, exist_ok=True)


def human_duration(d):
    if d < 1:
        return "Less than a second"
    elif d == 1:
        return "1 second"
    elif d < 60:
        return f"{d} seconds"
    elif d < 120:
        return "1 minute"
    elif d < 3600:
        return f"{d // 60} minutes"
    elif d < 7200:
        return "1 hour"
    elif d < 86400:
        return f"{d // 3600} hours"
    elif d < 172800:
        return "1 day"
    elif d < 604800:
        return f"{d // 86400} days"
    elif d < 1209600:
        return "1 week"
    elif d < 2419200:
        return f"{d // 604800} weeks"
    elif d < 4838400:
        return "1 month"
    elif d < 31536000:
        return f"{d // 2419200} months"
    elif d < 63072000:
        return "1 year"
    else:
        return f"{d // 31536000} years"


def list_files_by_modification():
    return sorted(Path().rglob('*'), key=lambda p: os.path.getmtime(p), reverse=True)


def list_cli(ramalama_store, args):
    if len(args) > 0:
        usage()
    print(f"{'NAME':<67} {'MODIFIED':<12} {'SIZE':<6}")
    mycwd = os.getcwd()
    os.chdir(f"{ramalama_store}/models/")
    for path in list_files_by_modification():
        if path.is_symlink():
            name = str(path).replace('/', '://', 1)
            file_epoch = path.lstat().st_mtime
            diff = int(time.time() - file_epoch)
            modified = human_duration(diff) + " ago"
            size = subprocess.run(["du", "-h", str(path.resolve())],
                                  capture_output=True, text=True).stdout.split()[0]
            print(f"{name:<67} {modified:<12} {size:<6}")
    os.chdir(mycwd)


funcDict["list"] = list_cli
funcDict["ls"] = list_cli


def pull_huggingface(model, ramalama_store):
    model = re.sub(r'^huggingface://', '', model)
    directory, filename = model.rsplit('/', 1)
    gguf_path = try_huggingface_download(
        ramalama_store, model, directory, filename)
    directory = f"{ramalama_store}/models/huggingface/{directory}"
    os.makedirs(directory, exist_ok=True)
    symlink_path = f"{directory}/{filename}"
    relative_target_path = os.path.relpath(
        gguf_path.rstrip(), start=os.path.dirname(symlink_path))
    try:
        run_cmd(["ln", "-sf", relative_target_path, symlink_path])
    except subprocess.CalledProcessError as e:
        print_error(e)
        sys.exit(e.returncode)

    return symlink_path


def pull_cli(ramalama_store, args):
    if len(args) < 1:
        usage()

    mkdirs(ramalama_store)
    model = args.pop(0)

    # Use glob to find files matching the pattern
    matching_files = glob.glob(f"{ramalama_store}/models/*/{model}")
    if matching_files:
        return matching_files[0]

    if model.startswith("huggingface://"):
        return pull_huggingface(model, ramalama_store)

    model = re.sub(r'^ollama://', '', model)
    repos_ollama = ramalama_store + "/repos/ollama"
    ramalama_models = ramalama_store + "/models/ollama"
    registry_scheme = "https"
    registry = "registry.ollama.ai"
    if '/' in model:
        model_full = model
    else:
        model_full = "library/" + model

    accept = "Accept: application/vnd.docker.distribution.manifest.v2+json"
    if ':' in model_full:
        model_name, model_tag = model_full.split(':', 1)
    else:
        model_name = model_full
        model_tag = "latest"

    model_base = os.path.basename(model_name)
    symlink_path = os.path.join(ramalama_models, f"{model_base}:{model_tag}")
    if os.path.exists(symlink_path):
        return symlink_path

    manifests = os.path.join(repos_ollama, "manifests",
                             registry, model_name, model_tag)
    registry_head = f"{registry_scheme}://{registry}/v2/{model_name}"
    return init_pull(repos_ollama, manifests, accept, registry_head, model_name, model_tag, ramalama_models, symlink_path, model)


funcDict["pull"] = pull_cli


def run_cli(ramalama_store, args):
    if len(args) < 1:
        usage()

    symlink_path = pull_cli(ramalama_store, args)
    os.execlp("llama-main", "llama-main", "-m",
              symlink_path, "--log-disable", "--instruct")


funcDict["run"] = run_cli


def serve_cli(ramalama_store, args):
    if len(args) < 1:
        usage()

    symlink_path = pull_cli(ramalama_store, args)
    os.execlp("llama-server", "llama-server", "-m", symlink_path)


funcDict["serve"] = serve_cli


def usage(cmd=""):
    print("Usage:")
    print(f"  {os.path.basename(__file__)} COMMAND")
    print()
    print("Commands:")
    print("  list             List models")
    print("  pull MODEL       Pull a model")
    print("  run MODEL        Run a model")
    print("  serve MODEL      Serve a model")
    sys.exit(1)


def get_ramalama_store():
    if os.geteuid() == 0:
        return "/var/lib/ramalama"

    return os.path.expanduser("~/.local/share/ramalama")


def in_container():
    if os.path.exists("/run/.containerenv") or os.path.exists("/.dockerenv") or os.getenv("container"):
        return True

    return False


def available(cmd):
    return shutil.which(cmd) is not None


def select_container_manager():
    if available("podman"):
        return "podman"

    if available("docker"):
        return "docker"

    return ""


def main(args):
    conman = select_container_manager()
    ramalama_store = get_ramalama_store()

    try:
        cmd = args[0]
        if conman:
            conman_args = [conman, "run", "--rm", "-it", "--security-opt=label=disable", f"-v{ramalama_store}:/var/lib/ramalama", f"-v{os.path.expanduser('~')}:{os.path.expanduser('~')}", "-v/tmp:/tmp",
                           f"-v{__file__}:{__file__}", "-p", f"{os.getenv('RAMALAMA_HOST', '8080')}:8080", "quay.io/ramalama/ramalama:latest", __file__] + args
            os.execvp(conman, conman_args)
        cmd = args.pop(0)
        funcDict[cmd](ramalama_store, args)
    except IndexError:
        usage()
    except KeyError:
        print(cmd + " not valid\n")
        usage()


if __name__ == "__main__":
    main(sys.argv[1:])
